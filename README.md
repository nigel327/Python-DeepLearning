# Python-DeepLearning
### Implementing Deep Learning Theoretical Principles with Python

Deep learning, as one of the three pillars of next-generation AI--the other two being big data and cloud computing, is a critical theoretical component for implementing various machine learning and AI technologies, ranging from Autopilot to ChatGPT. 

Simultaneously, the innovation of Python has grown dramatically in the last decade. You can use Python in statistics, website development, and facial recognition. On top of that, Python is also used in groundbreaking areas of IT, like machine learning and data science. And it makes Python one of the most practical tools for deep learning implementation.

In this repository, I only used Python to demonstrate the fundamentals of deep learning, with no assistance from third-party frameworks like TensorFlow or PyTorch. It is your first step toward deep learning. Initially, I wrote these notebooks and inline annotations in Chinese for my studies. And I'll keep this page updated with relevant notes for each topic. Please keep checking back later.

### List of Contents

1.	[Python Base for Deep Learning](./01.%20Python%20深度学习编程基础.ipynb)
2.	[Perceptron Neural Network](./02.%20感知机基础运算.ipynb)
    - Extension: [Perceptron Explained Using Python Example](https://dzone.com/articles/perceptron-explained-using-python-example-data-ana)
    - Extension: [Multi-layer Perceptron with Titanic Dataset](https://www.kaggle.com/code/androbomb/simple-nn-with-python-multi-layer-perceptron)
3.	Activation Functions
4.	Three-Layer Neural Networks
5.	Softmax Activation Function
6.	Batch Size
7.	Loss Functions
8.	Gradient Descent
9.	Learning Algorithms
10.	[Backpropagation](https://github.com/nigel327/Python-DeepLearning/blob/main/10.%20%E8%AF%AF%E5%B7%AE%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%B3%95.ipynb)
11.	 - Extension: [What is backpropagation doing?](https://www.3blue1brown.com/lessons/backpropagation)
     - Extension: [Backpropagation calculus](https://www.3blue1brown.com/lessons/backpropagation-calculus) 
12.	Backpropagation in Affine and Softmax Layers
13.	Backpropagation in Two-Layer Neural Networks
14.	Gradient Descent Stochastic and Momentum
15.	Gradient Descent Optimization
16.	Gradient Descent Optimization with MNIST
17.	Weights and Biases initialization
18.	Weights and Biases initialization with MNIST
19.	Batch Normalization
20.	Underfitting and Overfitting
21.	Weight Decay
22.	Dropout Algorithm
23.	Implementing Convolutional Neural Networks

### References
- [CS231n Python Numpy Tutorial](https://cs231n.github.io/python-numpy-tutorial/)
- [NumPy Illustrated: The Visual Guide to NumPy](https://medium.com/better-programming/numpy-illustrated-the-visual-guide-to-numpy-3b1d4976de1d)
- [Dive into Deep Learning](https://d2l.ai/)
- [Deep Learning from Scratch](https://github.com/oreilly-japan/deep-learning-from-scratch)
