# Python-DeepLearning
### Implementing Deep Learning Theoretical Principles with Python

[中文说明](./ChineseReadme.md)

Deep learning, as one of the three pillars of next-generation AI--the other two being big data and cloud computing, is a critical theoretical component for implementing a plethora of machine learning and AI technologies, ranging from Autopilot to ChatGPT. 

Simultaneously, the innovation of Python has grown dramatically in the last decade. You can use Python in statistics, website development, and facial recognition. On top of that, Python is also used in groundbreaking areas of IT, like machine learning and data science. And it makes Python one of the most practical tools for deep learning implementation.

In this repository, I only used Python to demonstrate the fundamentals of deep learning, with no assistance from third-party frameworks like TensorFlow or PyTorch. It is your first step toward deep learning. I wrote these notebooks and inline annotations in Chinese for my studies. And I'll keep this page updated with relevant notes for each topic. Please keep checking back later.

You can find the datasets in the notebooks by [this link](https://pan.baidu.com/s/1LFtqMtOZ4w2LeRfgFwm-fA?pwd=yek8).

### List of Contents

1.	Python Base for Deep Learning
2.	Perceptron Neural Network
    - [Perceptron Explained Using Python Example](https://dzone.com/articles/perceptron-explained-using-python-example-data-ana)
    - [Multi-layer Perceptron with Titanic Dataset](https://www.kaggle.com/code/androbomb/simple-nn-with-python-multi-layer-perceptron)
3.	Activation Functions
4.	Three-Layer Neural Networks
5.	Softmax Activation Function
6.	Batch Size
7.	Loss Functions
8.	Gradient Descent
9.	Learning Algorithms
10.	Backpropagation
11.	Backpropagation in Affine and Softmax Layers
12.	Backpropagation in Two-Layer Neural Networks
13.	Gradient Descent Stochastic and Momentum
14.	Gradient Descent Optimization
15.	Gradient Descent Optimization with MNIST
16.	Weights and Biases initialization
17.	Weights and Biases initialization with MNIST
18.	Batch Normalization
19.	Underfitting and Overfitting
20.	Weight Decay
21.	Dropout Algorithm
22.	Implementing Convolutional Neural Networks

References:
- [CS231n Python Numpy Tutorial](https://cs231n.github.io/python-numpy-tutorial/)
- [NumPy Illustrated: The Visual Guide to NumPy](https://medium.com/better-programming/numpy-illustrated-the-visual-guide-to-numpy-3b1d4976de1d)
- [Dive into Deep Learning](https://d2l.ai/)
- [Deep Learning from Scratch](https://github.com/oreilly-japan/deep-learning-from-scratch)
